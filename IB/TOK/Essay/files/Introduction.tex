\textbf{“Suspension of disbelief” is an essential feature of theatre. Is it essential in other areas of knowledge? Develop your answer with reference to two areas of knowledge.}

In a magic show, the beauty of cutting someone in half comes from knowing that no-one is actually being harmed \textendash\ in effect, accepting the premise that someone can be cut in half and be put back together however unlikely that may be. Similarly, a mathematical proof by contradiction works by further developing this idea: Accepting the premise that an assertion is true, following a series of logical steps and eventually reaching a contradictory statement, thus proving the original premise must be false. Both scenarios require the acceptance of an unlikely premise in order for value to be extracted, and it's this idea that will serve as our preliminary definition of \textit{suspension of disbelief}. It's important to note that while theatre arguably could not exist without suspension of disbelief, there has been plenty of mathematics and natural science done without it as will be discussed in this essay. This is not to say that it isn't important, but rather that the the expression is rather ill-fitting for use in this context, so the discussion on its essentiality focuses on the future development of mathematics and natural science where we can see its demand, and not the past.

Suspension of disbelief often requires a reconciliation of an ordinary and an extraordinary idea. This reconciliation can be illustrated via two situations concerning Bernhard Riemann's analytic continuation of Euler's zeta function. The process of analytic continuation is, in short, the expansion of the domain of a function \textendash\ meaning that, for example, $f(x) = \frac{1}{x}$ could be rewritten such that $f(0)$ is a defined number. Through this process, Riemann reached a representation of the zeta function that can be interpreted to mean that the sum of all natural numbers (1+2+3+4+\ldots) does not tend to infinite, but is $-\frac{1}{12}$. The use of the word \textit{interpreted} is imperative here, as it is the equivalent of stating that $\frac{1}{0}$ is not undefined, but rather an ``arbitrary'' number based on a series of strict mathematical principles. This unusual result has, in fact, an important application in string theory \citep[p.22]{Polchinski2005String}, but more importantly it shows how mathematicians and physicists are able to look at a divergent sum, which traditionally would simply be set aside, utilise a completely different methodology, and accept that both results can co-exist. The second situation to come out of Riemann's work is the Millennium prize worthy Riemann hypothesis \textendash\ arguably more correctly called Riemann conjecture. It states that all complex solutions to the zeta function lie on the strip with real part $\frac{1}{2}$ \citep[p.XI]{derbyshire2003prime}. This seemingly innocuous statement led to large implications regarding the distribution of prime numbers (called the prime number theorem), whose entire description is, in fact, based on this conjecture. A conjecture is largely an educated guess, and so drawing a theorem (what amounts to a fact) from it must require a very large degree of faith. So how is this degree of faith achieved? Interestingly, in a similar way to how natural science is done: observationally. Hundreds of solutions have been found exclusively along the so-called critical strip. This suggests that by accepting that good mathematics can be done from these \textit{a posteriori} truths, the field is opened to falsifiable explorations. This means that it moves away from only developing upon formulation of new theorems and closer to a thought-process similar to that of a proof by contradiction: accepting a dubious premise, developing it and upon finding an inconsistency, analysing whether it is due to a flaw in the premise or the methodology. In fact, this exact process is essential to the development of modern mathematics, allowing number theorists, for instance, to reach our current prime number theorem by taking large leaps that are often prefaced by the expression ``if the Riemann hypothesis is true, then \ldots'' \citep[pp.242]{derbyshire2003prime}.

Despite the presence of an unusual premise or a shift in paradigm, not all production of knowledge can be said to demand suspension of disbelief. Consider Mendeleyev's first attempts at creating the periodic table of elements: Upon observing a repetition in the characteristics of the elements, certain gaps could be left open in the table where undiscovered elements, he hypothesised, should be. This allowed Mendeleyev to delineate \textit{known unknowns}, e.g, knowing Germanium was likely to exist because an element with the characteristics fitting to its group and period was missing from the table \citep[p.101]{ChemIB2014Pearson}. John Newlands had a few years previously attempted a similar periodic table, but failed to account for unknown elements. The idea of grouping the elements in certain patterns was not new, and neither was a scientist's ability to recognise that there is value in precisely determining what is not known. So while Mendeleyev's work was responsible for an incredible leap forward in chemistry, and his understanding that imperfect knowledge was \textendash\ and is \textendash\ invaluable, equating the incremental development of science to the previous mathematics example, or even to the suspension of disbelief required in the theatre, is perhaps a little far-fetched. This subtle distinction might suggest that scientists and mathematicians are held to different standards, and that is indeed the case: the use of imperfect knowledge and observations is intrinsic to science, and the scientific method attempts to account for these imperfections; while mathematics, as previously discussed, is traditionally far more reliant on \emph{a priori} or definitional knowledge. 

A need for suspension of disbelief becomes more prominient as science becomes more abstract. In the turn of the 20th century, we saw, in parallel to the development of the atomic model, Einstein, Planck and other incredible physicists produce a series of experiments \textendash\ most important of which was the photoelectric effect \textendash\ which pushed scientists to accept that light may be both described as a wave and a particle. As early as the 17th century there have been debates on the nature of light, some that conclusively proved it must be a wave, such as the interference pattern seen when light is shone on a double-slit, and Maxwell's unification of magnetism, electricity and light. Einstein's photoelectric effect experiment stipulated a series of results that would be observed in case light were a wave, and a diametrically opposite set of results if it were a particle. The results observed favoured the particle option, and hence was born one of the most challenging set of ideas in all of science. Physicists were now faced with two completely different descriptions of light which in no way contradicted each other, explaining, in part, why there was now a demand for suspension of disbelief in natural science which was not present before. This is further reinforced by the advent of the quantum world. Natural science, and especially physics, moved away from macroscopic, natural analogies, such as explaining conservation of momentum through people inside boats throwing a ball to each other, to attempting to explain that in the quantum world, a cat may be simultaneously dead and alive. This forces us to simply have faith in the mathematics behind it \textendash\ as opposed to rationalising that a cat can, in some way, be both alive and dead. This faith is, in fact, even necessary in a more macroscopic level, as light is light, not wave nor particle, and it is our attempt to model its behaviour that leads us to the conundrum. It is this lack of intuitivity that demands, from both scientists and students of science, a more abstract understanding, and as the natural sciences move further and further into this world of abstraction, suspension of disbelief becomes as essential to it as it is in theatre.

In conclusion, despite the term \textit{suspension of disbelief} translating imperfectly to mathematics and natural science, it is clear that it plays a role in the development of knowledge in both areas \textendash\ especially when we consider the forefront of research. It is suggested that suspension of disbelief requires far more than a revolutionary concept, such as successfully grouping elements while accounting for those that are undiscovered, but rather the development of two equally correct ideas that contradict, but do not falsify each other. This is explored in mathematics through the analytic continuation of the zeta function, suggesting that the sum of all natural numbers may both be $-\frac{1}{12}$ or tend to infinity; and in science through light's wave-particle duality. In fact, the trend in both fields is to move away from macroscopic, natural analogies and towards requiring far more abstract comprehension, exemplified by Schr{\"o}dinger's cat that, macroscopically, is both dead and alive. The combination of these factors leads to the conclusion that while suspension of disbelief may have not been necessary in the past, this increasing difficulty for science to link itself to more relatable aspects of life, and mathematic's move toward \emph{a posteriori} truths, makes suspension of disbelief crucial to the future of both fields.

Word count: 1472

%Perhaps an example that even more strongly highlights our failure to translate and understand these concepts is that physicists had established that waves can act as particles, but could particles act as waves? De Broglie proved that they could. If the idea is scaled macroscopically, it means that with enough energy a person can go through a door and scatter just as light does, or when faced with two doors suddenly create an interference pattern. This is obviously impossible in practice.%

%Reflection: Fear that some of my points are anachronical, such as comparing something is taught to 7th graders (periodic table of elements) to complex analysis (thought in a mathematics undergrad program)%


% \textbf{Talk about this?}Mathematical developments which led to Andrew Wiles's solution to Fermat's last theorem. Frey, a German mathematician, accepted Fermat's last theorem as correct, and created an eliptic curve with the consequent properties. This made-up curve defied some characteristics stipulated to exist in all eliptic curves by the Taniyama-Shimura conjecture \citep{Lynch1997TheProof}. This acceptance of a premise was responsible for tying the proof of two seemingly unrelated conjectures in two discrete fields of mathematics.